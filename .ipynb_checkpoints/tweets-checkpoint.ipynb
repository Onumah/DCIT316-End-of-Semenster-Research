{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Extraction using the twitter API\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tweepy\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from textblob import TextBlob \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "#import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens\n",
    "API_KEY = 'kkBWYP1Vh3qwIUQZtnDcwZpSi'\n",
    "API_Key_Secret = 'LA2BILmgo8Jn2BiKsRCFa7muUyPqjE6aStNL96iT4E6dMlZOhn'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAALmDhAEAAAAAo00TTYY5BIu%2FcnSpPmpHGzlk7Ro%3Dw6fjC6W57HeVqQkthB5royMsaHfAkBBx9FoZNZmjUVvux8YSpK'\n",
    "client_ID = 'REx5dnpzS1ZiVGJrMG11SE5vTFo6MTpjaQ'\n",
    "client_Secret = 'e777iEEupUDprYJ3FjkbMdVH4do9r6J1ZPu3L85CBqbjOyqvvS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create authenticate object\n",
    "authenticate = tweepy.OAuthHandler(client_ID, client_Secret)\n",
    "\n",
    "#set access tokens\n",
    "authenticate.set_access_token(API_KEY, API_Key_Secret)\n",
    "\n",
    "#create client object\n",
    "client = tweepy.Client(bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make queries\n",
    "query = 'threat OR terrorism OR Jihad OR extremist OR violence -is:retweet lang:en'\n",
    "tweets = client.search_recent_tweets(query=query, max_results=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe\n",
    "tweets_df = pd.DataFrame([tweet.text for tweet in tweets.data], columns=['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @johnmoralestv: “in the span between sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @muradsaeedpti: shehbaz sharif,  maryam naw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@carbonlolly @aintscarylarry @dixoncox12 what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @jysexton: and it’s almost like the wealth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@paulallen262 @79blakey @navylookout @bwallace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rt @jkoff609: @ziggystardogs @paulstetson13 @d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>#thailand: according to data from the royal th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>uk: wembley hindu temple’s chairman gives a me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>rt @projectlincoln: joe biden was elected to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i support domestic violence from the woman in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets\n",
       "0   rt @johnmoralestv: “in the span between sunday...\n",
       "1   rt @muradsaeedpti: shehbaz sharif,  maryam naw...\n",
       "2   @carbonlolly @aintscarylarry @dixoncox12 what ...\n",
       "3   rt @jysexton: and it’s almost like the wealth ...\n",
       "4   @paulallen262 @79blakey @navylookout @bwallace...\n",
       "..                                                ...\n",
       "95  rt @jkoff609: @ziggystardogs @paulstetson13 @d...\n",
       "96  #thailand: according to data from the royal th...\n",
       "97  uk: wembley hindu temple’s chairman gives a me...\n",
       "98  rt @projectlincoln: joe biden was elected to r...\n",
       "99  i support domestic violence from the woman in ...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"Tweets\"] = tweets_df[\"Tweets\"].str.lower()\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing tweets\n",
    "\n",
    "#Cleaning the data\n",
    "#First approach \n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #removing @ mentions\n",
    "    text = re.sub(r'#','',text) #removing the # symbols\n",
    "    text = re.sub(r'rt[\\s]+','',text) #removing the RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #removing the hyperlinks\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    text = re.sub('[\\n]+', ' ', text)\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    text = re.sub(r'hxxps?:\\/\\/\\S+','',text)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    text = re.sub('[()!:?]', ' ', text)\n",
    "    text = re.sub(r'[0-9]+','',text) #removing numbers\n",
    "    text = re.sub(r'\\&\\w*;','',text) #removing html entities\n",
    "    text = re.sub(r'\\$\\w*','',text) #removing tickers\n",
    "\n",
    "    EMOJI_PATTERN = re.compile(\n",
    "    \"([\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"])\"\n",
    "    )\n",
    "    text = re.sub(EMOJI_PATTERN, r' \\1 ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>span sunday night early tuesday morning ian wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shehbaz sharif maryam nawaz massive audio leak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threat peace potus biden takes abandon b equip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost like wealth class equivocates authorita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>another budget january way world happening tod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  span sunday night early tuesday morning ian wi...\n",
       "1  shehbaz sharif maryam nawaz massive audio leak...\n",
       "2  threat peace potus biden takes abandon b equip...\n",
       "3  almost like wealth class equivocates authorita...\n",
       "4  another budget january way world happening tod..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to stem word\n",
    "\n",
    "\n",
    "#Applying functions to the  tweets\n",
    "#cleaned tweets\n",
    "tweets_df[\"Tweets\"] = tweets_df[\"Tweets\"].apply(clean_tweets)\n",
    "\n",
    "#removing stopwords \n",
    "stop_words = stopwords.words('english')\n",
    "tweets_df['Tweets'] = tweets_df['Tweets'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "#Tokenization\n",
    "#tweets_df['Tweets'] = tweets_df.apply(lambda row: nltk.word_tokenize(row['Tweets']), axis=1)\n",
    "\n",
    "#tweets_df['Tweets'] = tweets_df.apply(_stem)\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the cleaned data into a csv file\n",
    "tweets_df.to_csv('clean_data3.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "34561dfd8f3962dd49d83a99497a1476a39f7bcba9df00bfa2d514e2cab42334"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
